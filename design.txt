hproto - Human-friendly binary protocol message encoding
========================================================

Introduction
------------

hproto is a binary protocol message encoding similar to Google's "protocol buffers", "MessagePack", "BENCODE" "ASN.1", "XDR" or the author's own "aproto".

It is used by a sending process to encode ("marshal") the data structure of a software message as an opaque block of binary data, which can then be transferred by any means available to a receiving process, which decodes ("un-marshals") and re-assembles an equivalent message for local processing.

The scope of application for hproto is also similar to that of XML, YAML, RFC-822 and JSON, except that hproto is not a text-based encoding.

The outstanding property of hproto is the fact that the encoding is simple enough that an encoded message can be decoded by a human with the help of a hexadecimal dump of the message contents relatively easily.

In this regard, hproto is similar to BENCODE, although the actual encoding is much more similar to "protocol buffers".

Like MessagePack, hproto also sacrifices some encoding efficiency for simplicity, resulting in an encoding which is less compact than "protocol buffers" or "aproto", but not by much.

hproto has also some provisions for optionally allowing to define messages in such a way so that they can be modified in-place. This is not as powerful als Google's "flatbuffers" which have been created explicitly for this purpose, but also much simpler to implement and understand.


Protocol definition syntax
--------------------------

Like "protocol buffers", hproto provides a metasyntax for defining the structure of a message. This information needs to be known by both the sender and receiver of a message in order to understand the contents of the message.

"protocol buffers" uses ".proto" text files for storing this metasyntax information, while hproto uses - little surprisingly - ".hproto" files for the same purpose.

It should be possible to write a message compiler for .hproto files which can validate the syntax of those files and then synthesize code for automatic marshalling and unmarshalling of hproto messages.

But this has not been done yet and may never be done, because hproto is simple enough that it can be assembled mostly manually. It can also be decoded visually using only a hex dump of the encoded message and a copy of the associated .hproto file as a reference.

OK, and now for an example how hproto works. Let's assume we have the follwing C struct

struct person {
   char *first_name, *last_name;
   unsigned int born;
}= {"John", "Doe", 1990};

and want to encode it as binary hproto message blob ("binary (potentially) large object") for transport.

First, we create a file "person.hproto" for this message, containing the following definition:

message person {
   string first_name:0;
   string last_name:1;
   uint born:2;
};

This defines the fields which are allowed in the message and also assigned numeric field numbers to every field.

The syntax for the field numbers looks similar to that of bit fields in C. However, it is recommended not to put a space between the field number and the field name, because otherwise the inclusion of a default value (explained later) might look ugly.

Other than the field names which are only required in the proto files, the field numbers will actually be part of the encoded binary message as "tags numbers".

Next, one needs to know the encoding of a hproto message.

In this simple case, all fields can be encoded by writing their encoded values *followed* by a <type_octet> in which the high-nybble represents the field number and the low-nybble represents the length of the encoded field contents.

The last thing to know for this example is how to encode the data types "string" and "uint".

"string" is simple - it is just the bytes which make up the string.

So we start encoding our message with the first field "first_name", and write its string contents first:

$ # string first_name:0; /* "John" */
$ printf %s John | hexdump -C
00000000  4a 6f 68 6e                                       |John|
00000004

So we encode this as the hex bytes

4a 6f 68 6e

which start our encoded message.

Now we have to append the <type_octet> as 0x04: It the field number is 0, and the size is 4 bytes. This completes our first encoded field as

4a 6f 68 6e 04

Now for the second field:

$ # string last_name:1; /* "Doe" */
$ printf %s Doe | hexdump -C
00000000  44 6f 65                                          |Doe|
00000003

We encode this as the hex bytes

44 6f 65 13

The "1" in the trailing "13" is the field tag for "last_name". The "3" is the length of the string.

Now for the last field, which is of type "uint".

"uint" is the big-endian base-256 representation of the unsigned integer. As a special optimization, an uint with a <field_contents> size of 0 bytes is allowed and then represents the numeric value zero. (This might be a very useful optimization, because zero is a very frequent value in many applications.)

Next we need to know that "big-endian base-256 representation" is just a pompous way of saying that the hex dump of the encoded unsigned integer looks exactly the same as the integer written as a multi-digit hexadecimal number with a leading "0" digit in case of an odd number of hexadecimal digits in the multi-digit representation.

Example: Hex integer 0x1a will encode to hex dump "1a", 0xf will encode as hex dump "0f", 0x12345 will encode as hex dump "01 23 45" etc. Simple!

Now we can continue with encoding the third field:

$ # uint born:2; /* 1990 */
$ printf '%x\n' 1990
7c6

We encode this as the hex bytes

07 c6 22

where the "07 c6" are the hex dump for the decimal value 1990 expressed in hexadecimal (0x7c6).

The left "2" in the trailing "22" is the field number for "born". The right "2" is the length of the field in bytes.

The complete hproto message encoding is therefore:

4a 6f 68 6e 04 44 6f 65 13 07 c6 22

For decoding this message, one has to start from the right and cut the message into fields based on the length of the field's trailing <type_octet> bytes:

4a 6f 68 6e [04] | 44 6f 65 [13] | 07 c6 [22]

I have used "|" here to show field boundaries and put the <type_octet>s within square brackets.

Now for another example: Given the hproto definition

message coord3d {
   int x:0;
   int y:1;
   int y:2;
};

decode the following encoding for an instance of such a message:

4a 01 10 8b 21

In order to do that, you need to know how hproto encodes an "int". It does this by encoding the signed integer into an unsigned integer first using "zig-zag encoding", and encode the result as an "uint".

Zig-zag encoding has been borrowed from Google's "protocol buffers" works as follows:

* Every non-negative signed integer u is encoded as the even unsigned integer 2 * u.

* Every negative signed integer n is encoded as the odd unsigned integer -2 * n + 1.

Zig-zag decoding:

* Every even unsigned integer e decodes into the positive signed integer e / 2.

* Every odd unsigned integer o decodes into the negative signed integer (o - 1) / -2.

With this new knowledge, we start by splitting the message into fields and <type_octet>s:

4a [01] | [10] | 8b [21]

and decode this as:

field #0 ("x") = zigzag_decode(0x4a) = 37
field #1 ("y") = zigzag_decode(0x00) = 0
field #2 ("z") = zigzag_decode(0x8b) = -69

Whe the 0x00? Well, as explained before, a zero-sized "uint" represents the numeric value zero even though no space for the actual value has been included in the message.

So, the message decodes as

message coord3d {
   int x:0;
   int y:1;
   int y:2;
}= {37, 0, -69};


hproto Message "wire" Encoding
------------------------------

Examples are fun. But now for the full picture!

A hproto message encoding is an unordered collection of fields, much more like a hash rather than a C "struct". The fields within the message are identified by their tag number rather than by their order.

The actual message encoding is just a concatenation of field value encodings.

The whole message structure is intended to be parsed from *behind*.

Because not all transports may provide the message size reliably or at all, the whole message may optionally be preceded with its length:

[ <size_of_encoded_actual_message> ] <encoded_actual_message>

If such a size prefix shall be present and how many bytes shall be used for encoding it (as a base-256 big-endian unsigned integer) must be defined in the protocol definition. There is no such prefix by default.

Within the actual encoded message, each field value encoding has the following structure:

<field_contents> [ <external_tag> ] [ <external_length> ] <type_octet>

Only <type_octet> and <field_contents> are actually necessary for every field, and <field_contents> has a variable size which can also be zero.

<type_octet> consists of two bitfields with 4 bits each, which will be represented by single hex-digits in a hexdump of the message:

* The left hex-digit of <type_octet> encodes the tag number of the field.
* The right hex-digit of <type_octet> encodes the byte size of the field contents.

The tag number is encoded directly within <type_octet> if its value is less than 0x0e. Otherwise, <external_tag> is present and contains the actual tag number as a big-endian base-256 unsigned integer.

The byte size of the field contents is encoded directly within <type_octet> if its value is less than 0x0c. Otherwise, <external_length> is present and contains the actual tag number as a big-endian base-256 unsigned integer.

The byte size of the <external_tag> field itself is determined by the value of the left hex-digit in <type_octet>: 1 if it is 0x0e, 2 if it is 0x0f, 0 otherwise.

The byte size of the <external_length> field itself is determined by the value of the right hex-digit in <type_octet>: 1 if it is 0x0c, 2 if it is 0x0d, 4 if it is 0x0e, 8 if it is 0x0f, 0 otherwise.

That's all one needs to know for the encoding of the basic message structure!


Optional message size prefix
----------------------------

As explained before, it is optionally possible to prefix the actual message encoding with its size, for cases where the exact message size will not be provided by the transport.

This size will be encoded as an "uint", but with a fixed field width in octets that must be defined in the hproto file.

In order to do this, include the following declaration as the first item within a message declaration (before any field definitions):

size-prefix only at top-level with N octets;

where "N" is the number of bytes to be used to represent the fixed-size length prefix field. Note that N must be large enough to be able to store the actual size of the message, no matter how large it gets.

This declaration has only an effect if the message is used as the top-level message. That is, it has to be the "outermost" message in case of nested messages.

When the same message type is used as a nested message within other messages within the same protocol, no size-prefix will be added to the nested messages.

Also note that such a "size-prefix"-declaration is irrevocable - once a revision of a protocol has been declared that way, later revisions cannot change the declared byte-size of the prefix field or remove it entirely. (The only way to do that would be to define a different type of message with a new name or define a new protocol.)

However, it is not a problem to add such a declaration at a later revision, if no such declaration has been present before: In this case, clients still using older protocol revisions will see the size-prefix as "leading garbage", but it will not change the way the messages are parsed from behind.

Clients should generally ignore leading garbage when decoding messages, and maintain the garbage when just forwarding messages uninterpreted.


Why the heck is the message parsed from behind?
-----------------------------------------------

One might point out that

<type_octet> [ <external_tag> ] [ <external_length> ] <field_contents>

would have been a more intuitive and more sane way to define the data structure layout for encoding a message.

Actually, the initial design for hproto used exactly this layout. However, this design was revised.

The reason for this was ease in constructing the message: the sizes of all variable-sized fields will already be known when they have to be written. This allows a message to be constructed in a single pass in-place. No data needs to be moved or copied after it has been written into the output buffer for "optimizing" the message layout.

And when parsing an existing message in a memory buffer, it generally does not matter in which direction the pointer which keeps track of the current parsing position does move.

Parsing from behind allows a message creator to write the <field_contents> first without having to know the size in advance, like writing to a stream (assuming the buffer is large enough, reallocating as necessary). Once this has been done, the exact size of the <field_contents> is known, and the writer can choose the most efficient encoding for the field length and write this last.


I have an 8-bit CPU, I do not want to support 64-bit field sizes
----------------------------------------------------------------

You don't have to! The fact that hproto messages can contain 64-bit wide size fields does not mean that every conforming application has to support those.

In fact, every hproto implementation is free to typedef a type of its choice for internally storing field sizes.

For instance, an 8-bit implementation may decide to not support any field lengths wider than 8 bits.

Such an implementation must still recognize that a messages includes a 16-, 32- or 64-bit size field if this is the case.

But it is free to reject the reception of such a message with an error message, stating that the message contents exceed the application's limits or that the message itself is too large to be examined.

In fact, even 64-bit implementations of hproto should reject messages of unreasonable sizes. Because otherwise the application could become a victim of dDoS-attacks where an attacker sends gigantic messages until the victim runs out of RAM.

Receivers and senders of hproto messages should share an idea what amount of data to maximally expect in a message, and should refuse to accept messages larger than that. 

Rejecting messages assumed some sort of back-channel of course.

In situations where this is not possible such as using UDP, applications should just ignore messages which are too large or contain field widths for sizes they cannot handle. After all, UDP does not guarantee any reception at all. So the receiver is free to pretend it never got the message.


More example field contents encodings
-------------------------------------

The encodings in our first examples have been easy because all tag numbers and field contents lengths could be represented directly within <type_octet> and neither <external_tag> nor <external_length> where required.

So let's define a more complex message which needs both extended fields:

struct person2 {
   char *first_name;
   char *last_name;
   struct bigint *favorite_fermat_prime;
}= {
     UTF7_2_UTF8("G+APw-nther"), "Brunthaler"
   , STR_2_BIGINT("162259276829213363391578010288127")
}

message person2 {
   utf8_string first_name:8;
   utf8_string last_name:0x23;
   uint favorite_fermat_prime:0x4567;
};

We use the type "utf8_string" here instead of just "string", because we want to use a particular encoding (UTF-8) for the contents of the string.

Note that we can actually use any types we want in the .hproto message definitions, because there is no compiler/verifier for it yet. It is strictly provided as a documentation of the intended message layout for the benefit of human developers.

As one can see, the field number tags in the hproto files must actually be provided as hexadecimal numbers. This was not obvious in our previous example because we only used tag numbers no larger than 9, which are the same in decimal and hexadecimal.

The reason why field numbers must be provided in hexadecimal is the fact that you will also see them in this form in the hex dump of a message.

We also remember from the explanation of the field number encoding that there are actually 3 different classes of field numbers which are encoded differently:

type_octet "Nx" with <external_tag> N from 0x00 through 0x0d
type_octet "ex" NN with <external_tag> NN from 0x00 through 0xff
type_octet "fx" NN NN with <external_tag> NNNN from 0x0000 through 0xffff

where "x" does not matter (it represents the field length).

Now let's encode the actual fields:

$ # utf8_string first_name: 8 = UTF7_2_UTF8("G+APw-nther")
$ printf %s G+APw-nther | iconv -f UTF-7 -t UTF-8 | hexdump -C
00000000  47 c3 bc 6e 74 68 65 72                           |G..nther|
00000008

This are 8 UTF-8 bytes with field tag 8, which will be encoded as

47 c3 bc 6e 74 68 65 72 88

$ # utf8_string last_name: 0x23 = "Brunthaler"
$ printf %s Brunthaler | iconv -t UTF-8 | hexdump -C
00000000  42 72 75 6e 74 68 61 6c  65 72                    |Brunthaler|
0000000a

This are 0x0a bytes with field tag 0xe23, which will be encoded as

42 72 75 6e 74 68 61 6c 65 72 23 ea

Here the "23" are the <external_tag> which is present because the "e" in the "ea" defines a 1-byte <external_tag> to be present. The "a" in the "ea" is the byte length of the UTF-8 encoded string, and the remaining bytes represent the string contents.

$ # uint favorite_fermat_prime: 0x4567 = STR_2_BIGINT("162259276829213363391578010288127"
$ echo "obase=16; 162259276829213363391578010288127" | bc | tr A-F a-f | { read x; expr ${#x} % 2 != 0 > /dev/null && x=0$x; printf '%02x\n' `expr ${#x} / 2`; echo $x | fold -w 2 | paste -s -d " "; }
0e
07 ff ff ff ff ff ff ff ff ff ff ff ff ff

The first line of the output is the number (0x0e) of the following bytes, and the second line is just the hexadecimal representation of the large prime number. We encode this as

07 ff ff ff ff ff ff ff ff ff ff ff ff ff 45 67 0e fc

The "f" in the "fc" means that we use a 2-byte <external_tag>, which is represented by the bytes "45 67" which are the big-endian base-256 representation of the value 0x4567.

The "c" in the "fc" means that the length of the contents is too large to be encoded directly as the 2nd hex digit of the <type_octet>. Instead, a 1-byte <external_length> is used to represent the actual length. This is the byte "0e" in the encoding. The remaining bytes which precede those trailer fields represent the prime number as an unsigned integer with the value 0x07ffffffffffffffffffffffffff.

Together, the complete message hproto-encodes as

47 c3 bc 6e 74 68 65 72 88 42 72 75 6e 74 68 61 6c 65 72 23 ea 07 ff ff ff ff ff ff ff ff ff ff ff ff ff 45 67 0e fc


Here is a chart for decoding hproto messages based on their hex dump (starting with the last byte of the message):

0? - d?: Tag number is directly encoded as 0x00 through 0x0d.
e?: Tag number precedes as 1 byte
f?: Tag number precedes as 2 bytes (big-endian base-256 representation)
?0 - ?b: Field contents byte length is directly encoded as 0x00 through 0x0b.
?c: Contents length precedes as 1 byte
?d: Contents length precedes as 2 bytes (big-endian base-256 representation)
?e: Contents length precedes as 4 bytes (big-endian base-256 representation)
?f: Contents length precedes as 8 bytes (big-endian base-256 representation)

In all cases, the optional <external_tag> precedes the optional <external_length>, and both are located between the the optional <field_contents> and <type_octet>.

After those examples, some clarifications.

There are no "required" fields in a message. All fields can be missing, which will then behave like a "NULL" value in SQL (i. e. "value not present").

message person {
   string first_name:0;
   string last_name:1;
   opt married:2;
};

If the type "opt" is implemented as an empty string (encoded as "20" for tag number 2 and zero length) and the presence of the field means the option applies, then the missing field means that the option does not apply.

That is, the presence of a "20" field encoding as a message field means the person is married. Otherwise the person is not married.

It is also possible to define a default value in the hproto file. If the field is missing in the message, then the field is assumed to have the default value as its contents.

message person {
   string first_name:0;
   string last_name:1;
   string marital_status:2 = "single";
};

This means that if a field with tag number 2 is present then it represents the marital status as a string. Otherwise, the string "single" will be used as the status even though it is not actually present in the message and would be NULL without the default declaration.

When creating a message, a field can be omitted from the encoding if the value to be encoded equals the field's default value. This is just an optimization, though, and not a requirement.

So far, the length of the <field_contents> have always been determined by the minimum number of bytes required to represent the contents.

However, for messages which are to be edited in-place, it might be a good idea to make the field length that of the maximum supported length of the content.

For instance, if we want to store a 24-bit RGB color encoded as an unsiged integer 0xRRGGBB

message rgb_color {
   uint rgb24:9;
};

then the color black 0x000000 could easily be encoded as

90

(remember that an uint of size 0 represents the value zero) because 0x000000 and 0 are the same integer.

However, if we want to make this message editable in-place, we need to ensure that it will always use 3 bytes for the encoding, even if it means to store leading zeros, so that the value can be replaced with an arbitrary RGB value later.

This can be enforced as follows:

message rgb_color {
   uint rgb24:9 (zero-leftpad to 3 octets);
};

This means that if the field contents need less then 3 bytes to encode, then it will be padded to 3 bytes by adding zero bytes at the left. "zero-rightpad" does the same but adds the pad bytes at the right side (this type of padding is useful for strings).

The term "octet" is used instead of "byte" to make clear that 8-bit bytes are meant. Historically, bytes with bit sizes other than 8 bits are known to have existed on some hardware platforms. "octet" always means an "8 bit byte".

Generally, a comma-separated list of such and similar attribute declarations can be placed within parentheses before the end of the field declaration.

Like for tag numbers, only hexadecimal numbers are allowed for zero-rightpad declarations in order to avoid base conversions when examining the hexdump of a message. And again the 0x-prefix is optional for hex numbers up to 9.

In the case of this example, "3" means direct encoding within the <type_octet>. It ensures that the color black would be encoded as

00 00 00 93

The "9" is the tag number, the "3" is the field contents width directly encoded in the <type_octet>, and the "00 00 00" is the 24-bit fixed-width RGB encoding of black.

Another example:

message nested_string {
   string text:6;
};

message song {
   uint track:3 (zero-leftpad to 1 octet);
   nested_string artist:5 (zero-rightpad to 0x20 octets);
   nested_string title:7 (zero-rightpad to 0x40 octets);
   nested_string description:4 (zero-rightpad to 0x400 octets);
};

Such a message will have the following encoding:

<track_uint> 31 <artist_string>... 20 5c <title_string>... 40 7c <description>... 04 00 4d

Note that the fields ending with "..." are nested fields which include their own length. The idea is that the "inner" length specifications define the actual length of the field contents, where the zero-rightpad width just ensures that there is enough space for increasing the inner length in-place.


Field data types
----------------

The basic hproto wire-encoding does not care about field types. They must be learned by looking into the declarations of the *.hproto files. The wire-encoding treats all data types just as opaque octet-strings.

The following list gives a list of type names which can be used to declare particular data type encodings for fields within *.hproto files.

You are invited to invent your own data types in addition to those declared here. However, the types declared here shall always be interpreted as described here. If you don't like those encodings, just don't use them and create your own encodings using with other names instead.

* A nested message. This is actually not a particular type name, but is rather represented by the name given to a different "message" declaration. Such defined message types can be used as fields in other messages. This is encoded as a byte string, i. e. the field is encoded like a string and contains the complete hproto-encoding of the nested message as its contents.

* "uint" - an unsigned integer of arbitrary magnitude, encoded as a big-endian integer (written from left to right starting with the most significant digit and followed with increasingly less significant digits). This encoding uses a number-system with radix 256, where every "digit" is represented by an octet. Therefore, the shortest possible encoding for integer 0x12345 will be the byte-sequence 01 23 45. As an optimization, an "empty" uint (i. e. one with a <field_contents> length of 0 bytes) is defined to represent the value 0. Note that this encoding is quite different from Google's "protocol buffers" which use a much more complicated base-128 encoding which requires bit-shifting to decode/decode the values. The hproto "uint"-encoding does not require any bit-shifting.

* "int" - a signed integer of arbitrary magnitude. This is encoded as an "uint" after "zig-zag"-encoding the signed integer value as an unsigned integer. Zig-zag-encoding maps signed integers into unsigned ones as follows: 0, -1, 1, -2, 2, -3, 3, -4, 4, ... are mapped to unsigned 0, 1, 2, 3, 4, 5, 6, 7, 8, ..., respectively. The encoding alternates by describing the next unsigned number and the next signed number not yet described. The unsigned numbers start with 0 and the signed numbers start with -1. Note that this zig-zag-encoding has been "borrowed" from Google's protocol buffers.

* "string", "locale_string", "any_string" - a text string of unspecified encoding or character set. Use this to pass through string values where the encoding is unknown or subject to change. Use "any_string" if the string is known to potentially use different character sets or character encoding depending on the circumstances or changes regularly. Use "string" if you just don't care about the character encoding, and don't even want to know such details. Use "locale_string" if the string will use the character set and encoding defined by the locale which is currently in effect, whatever it may be.

* "octetstring", "bytestring" and "opaque" - a string containing binary bytes that are not necessarily text but may as well be such. The name "bytestring" is deprecated. "octetstring" should be used it it is important/relevant that the string consists of 8-bit bytes. "opaque" should be used to describe a BLOB of data without known (or cared about) internal structure.

* "utf8_string" - a UNICODE string in UTF-8 encoding without a particular normalization form. That is, such a strings may contain a mixture of NFC- and NFD-encoded UNICODE characters.

* "utf16_le_string" - a UNICODE string in UTF-16LE encoding without a particular normalization form (see "uft8_string"). No BOM is used, little-endian representation is mandatory.

* "utf16_be_string" - a UNICODE string in UTF-16BE encoding without a particular normalization form (see "uft8_string"). No BOM is used, big-endian representation is mandatory.

* "utf16_default_le_string" - a UNICODE string in UTF-16 encoding without a particular normalization form (see "uft8_string"). A BOM may be used to indicate the byte order. Without a BOM, the byte order must be little-endian.

* "utf16_default_be_string" - a UNICODE string in UTF-16 encoding without a particular normalization form (see "uft8_string"). A BOM may be used to indicate the byte order. Without a BOM, the byte order must be big-endian.

* "latin1_string" - a UNICODE string which is restricted to the first 256 UNICODE code points, also known as the LATIN1 or ISO-8859-1 character set. Note that this type is probably not very useful any more as it cannot represent the EURO sign. However, it is the most compact and powerful encoding of UNICODE which does not contain any multi-byte encodings. It is also a superset of ASCII and contains most umlauts and diacritics used by western languages.

* "ascii" - a UNICODE string which is restricted to the first 128 UNICODE code points, also known as ASCII, US-ASCII or IA85. It represents all characters als octets with the most significant bit set to 0.

* "ebcdic" - this is just included for completeness. EBCDIC is a character set mostly used on ancient IBM mainframes. It has little significance nowadays, but may still be encountered when dealing with historic data records or ancient applications. It is a 7-bit character set like ASCII, but assigns the characters in a different way to codepoints.

* "boolean": A restricted subtype of "uint" where only the values 0 and 1 are allowed. Note that this is actually a tri-state rather than a real boolean value, because the value can also be NULL if the field is not present at all in the message encoding. NULL could then be interpreted as a third state "maybe" or "undecided". Encoded the same as "uint", including the optimization that an empty <field_contents> represents the value 0 (and thus "false"). However, when defining a default value for such a field, only the words "true" and "false" shall be allowed in a message definition. You can define your own "bool" if you don't like this definition.

* "float": A single-precision floating-point number, using exactly the exact same bit layout as a "float" in the C programming language on the local machine. This type is inherently hardware-specific and may even depend on compiler options. It is therefore non-portable. However, it is normally safe to use for communication between different processes running on the same machine, of if the communication is restricted to other machines sharing the same floating point format details. It has also the advantage of zero conversion overhead.

* "double": A double-precision floating point number. See the documentation for type "float", replacing any referenced to the term "float" with "double".

* "pfloat": A portable floating point number. This is in fact a predefined "message pfloat {int mantissa:0 = 1; uint radix:1 = 2; int exponent:2 = 0}" which contains everything necessary to represent a floating point number of any radix base from any platform with maximum precision portably and exactly. This type may have a shorter or longer encoding than "float" and "double", depending on the bit pattern of the value to be encoded. Use this type for portable communication between machines with unknown or different internal floating point implementations or byte orders. Note that <mantissa> is usually more than just the mantissa of a "float"/"double", as it actually includes its most significant bit (no implicit "1" bit) as well as the sign of the number. The value of the exponent will also be adjusted to compensate for the fact that <mantissa> is an integer rather than a fractional value. Special values are represented by <mantissa> == 0 with the following predefined values for <exponent> in those cases: +0.0 == 0, -0.0 == -1, +INF == +2, -INF == -2, NaN == +3, IND/QNaN == -3. "INF" means "Infinity", "NaN" means "Not a Number", "QNaN" means "Quiet/Signaling NaN", "IND" means "indeterminate number". Denormal numbers need no special encoding in this definition because they are not encoded specially in pfloats. Note that while this format can store all known floating-point formats without loss of precision, this does not mean that your platform's native floating-point support can do the same. This means that a conversion from float or double into "pfloat" is intended to be lossless, but this may not be true in the opposite direction. But even if some rounding might be unavoidable when converting to a native "double" depending on the platform, "pfloat" is still your best option of exchanging binary (or decimal) floating point numbers in the most platform-neutral way possible. Also note that not all platforms may support all features of "pfloat" such as NaNs - the conversion might fail in such cases, and need to be handled specially by the application. As a finishing remark, note that you always the option of using a portable software library such as libmpfr which supports arbitrary precision, rather than using your platform's native floating-point support.

* "decimal": This is a radix-10 floating point number with an integer mantissa and a non-positive exponent. Which means the exponent only expresses how many of the right-hand digits of the mantissa are fractional digits, but it cannot shift the mantissa to the left. "decimal" can store decimal numbers with any number of integral and fractional digits exactly. "decimal" is in fact implemented as a predefined "message decimal {int integral:0 = 0; uint base10_exponent:1 = 0}". For simplicity, there is no support for "special" values like NaN or INF when mantissa == 0 - the exponent has no effect in that case and should also be 0 to save space (but this is no requirement). If you want such special values, use "pfloat" instead which also can represent decimal fractional digits exactly. Actually, "decimal" is very similar to "pfloat", except that it implies a radix of 10 and normalization is somewhat easier, because the exponent can never be positive. Most of the time, "dfix4" will produce shorter encodings than "decimal". But "decimal" can store an unrestricted amount of fractional digits exactly.

* "dfix1": This is a decimal number with exactly one fractional digit. It is simply stored multiplied by 10 as an "int". This type is more space-efficient than "dfix4" if the fractional digit is frequently different from zero. Otherwise, if its is known that the vast majority of values to be encoded are in fact integral values without a fractional digit, "dfix4" will be more space-efficient.

* "dfix2": This is a decimal number with exactly two fractional digits. It is simply stored multiplied by 100 as an "int". Note that this encoding might actually be longer than that of "dfix4" if there are trailing fractional zero digits.

* "dfix4": This is a decimal number which can store up to 4 fractional digits. Actually, it can store either 0, 1, 2 or 4 decimal digits. A "dfix4" is internally stored as an "uint", which is composed of two values: m * 4 + f. That is, "f" is a 2-bit bitfield, and "m" is the remaining arbitrarily-sized integer part. "m" will then further be interpreted as a signed "int" (using zig-zag-encoding), and "f" determines the number of fractional decimal digits which are present at the right-hand side of the (now signed) "m". This number of fractional digits calculates as follows from "f": 2 raised to the power of "f", then reduced modulo 8. (In C this can be calculated as "1 << f & 7".) In other words, f == 0 means 1 fractional digit, f == 1 means 2 digits, f == 2 is 4 digits, and f == 3 means no fractional digits at all. "dfix4" is well suited to space-efficiently store monetary amounts for most currencies which rarely need more than 2 or 4 fractional digits. It may not be accurate enough to store bitcoin fractional values, though. Use a "decimal" in those cases which can store an unrestricted amount of fractional decimal digits exactly.

* "rational": This is in fact a predefined "message rational {int numerator:0 = 1; uint denominator:1 = 1}" which contains everything necessary store a fraction exactly. The fraction does not need to be normalized, although the application is of course free to do so. The following special values are supported: INF == +1/0, -INF == -1/0, IND/QNaN == 0/0. Note that there are an infinite number of additional ways to represent INF and -INF, but only the values above shall be taken as actual synonyms. There is no plain NaN. It is implementation-defined whether display formatting functions use the symbolic names or just display numerator and denominator as-is, i. e. as numbers.

* "bitvector": This is a binary packed array of bits, stored as an "octetstring". The first octet stores the bits with indexes 0-7, the second octet stores bits 8-15, etc. Within every octet, the least significant bit stores the bit with the lowest array index of that octet, and the most significant bit refers to the highest array index of that octet. It is allowed to write bits beyond the current actual size of the array, bitvector will automatically be enlarged if necessary. There is an infinite number of virtual "0"-bits beyond the last actually allocated octet in the array, which will be returned when reading without growing the array. This allows the optimization that a "bitvector" with 0 octets of <field_contents> will actually represent a vector filled with infinite many "0" bits. Also, writing a "0"-bit will never grow the array for the same reason. The API shall provide the information what the highest actually allocated bitvector-index is. Because bits are not necessarily booleans, the values "0" and "1" are considered to be small integers, rather than abstract symbols like "true" or "false".

* "serialdate": The number of days between 2000-01-01 and a given target date at the same place, both dates specified in the local time of that place. This number is internally expressed (and encoded as) an "int". That is, 2000-01-01 is encoded as 0, 2000-01-02 is encoded as +1, 1999-12-31 is encoded as -1, etc. The calculations are done using the rules of the Gegorian calender, which is the standard in Western countries, and was introduced on 1582-10-15, which is also the earliest date which should be represented as a "serialdate". Leap seconds cannot have any effect on the calculation, because only whole days are considered.

* "tzoffset": The offset of some time zone (typically the local one) from UTC, encoded as an "int", expressed as 15-minute-intervals (most time zone offsets are whole hours, but some are offset by 30 or 45 minutes - all of those can be expressed as multiples of 15 minute intervals). The value 0 means UTC. In other words, time_as_UTC + 15 * tzoffset * minutes == time_in_associated_timezone.

* "serialtime": The number of seconds elapsed since midnight of some day at some place, always using the time zone offset which was in effect at exactly that time at that place. Let's say, at the start of that day daylight saving was not in effect, but later that day it became effective. If serialtime is calculated from a time before daylight saving became active, it is based on the same "tzoffset" as the start of the day. Otherwise, it is based on the same "tzoffset" as the next day, which already includes the daylight saving offset. It assumes all minutes have exactly 60 seconds. The conversion of "serialtime" and HH:MM:SS is based on calendar time, and will not care about leap seconds (encoding some time [$MM]:60 will decode incorrectly as [$MM+1]:00 - the Linux "date" utility has exactly the same problem). This means "serialtime"-values will never be larger than 24 hours, even if daylight saving started or ended during that day. Even though the conversion itself does not care about leap seconds, the operating system functions which get the current HH:MM:SS normally do. So, as long as the time is actually obtained from such a function before converting it to "serialtime", the time expressed by that "serialtime" value will be correct subtracting two such values will usually calculate the correct time difference, including any leap seconds. This assumes the time stamps are from the same place and date, however. Otherwise, you need to include the "tzoffset" as well as the "serialdate" in the calculation as well, or the timestamps will not be comparable.

* "localdatetime": This is in fact a predefined "message localdatetime {serialdate date:0; serialtime time:1 = 0}" which contains everything necessary to compare two timestamps taken at the same place (with regard to the timezone) on possibly different dates.

* "globaldatetime": This is in fact a predefined "message globaldatetime {serialdate date:0; serialtime time:1 = 0; tzoffset tzo15m:2 = 0}" which contains everything necessary to compare two timestamps taken at two possibly different places (with regard to the timezone) on possibly different dates. Note that the timezone resulting from the default value for tzo15m will be UTC.


Adding custom type names
~~~~~~~~~~~~~~~~~~~~~~~~

The above list is *not* intended to ever be extended, which might otherwise create future name collisions. So there is no need to name your types X-something out of fear of future enhancements of hproto. Name your own type "int32" or "complex" if you like. Of course, defining any new types creates a responsibility for you to document the details of your encoding, preferrably as comments (or at least a reference where the details can found) in the hproto definition file.


Notable missing predefined data types
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Even though it is possible to add any desired missing data type as custom type names, I will explain here why some popular data types have not been predefined.


int32, int64 etc.
^^^^^^^^^^^^^^^^^

The existing "int"/"uint" can represent each of those without any disadvantage in terms of encoding efficiency. Together with the "zero-leftpad"-attribute declaration fixed-width encodings of are also possible.

utf32_string
^^^^^^^^^^^^

UTF-32 encoding is only interesting as an in-memory representation for simpler processing. It makes no sense as an external encoding, because there is no UTF-32 encoding which cannot be replaced by a same-length or shorter equivalent UTF-16 encoding. An UTF-32 encoding of some text is always larger or the same length as UTF-16, but will never save space. Generally, western languages are most efficiently encoded as UTF-8, while eastern CJK languages are most efficiently encoded as UTF-16.


UNICODE normalization qualifiers
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For those of the above UNICODE-based string types which can potentially represent UNICODE characters normalized as NFD, the type name may optionally be preceded by one of the following qualifiers: NFC, NFD, NFKC, NFKD. Those specify that the string values for that field are required to be normalized according to the UNICODE normalization format of the same name. If you have no idea what UNICODE normalization is, you probably won't need it. The qualifiers mean that any specified default constant for such a string must be normalized in the same way, because the protocol compiler won't convert anything. However, it MAY present an error in such a case (more likely though it won't care). Neither is the run-time required to check for normalization compliance (though it might). Therefore, those qualifiers are primarily a hint to the human reader what sort of normalization is expected/required.


UNICODE compression qualifiers
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For those of the above UNICODE-based string types which uses multibyte encodings for at least some of its UNICODE characters, and preceding the UNICODE normalization qualifier (if any, as it is optional), one of two further optional qualifiers is allowed: "SCSU-compressed" and "BOCU-1-compressed". They declare that the UNICODE string in this field is expected to be compressed with the compression scheme named after the qualifier. It also means that any declared default value will be encoded this way before actually being used. Like the normalization qualifiers, those compression qualifiers will have no effect on the run-time or the protocol compiler, other than compressing any associated default string literal in the specified way. And the first version of the protocol compiler certainly won't support that, meaning that for now string fields with that qualifier must not have an explicit default value.


Current state of implementation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Finally note that most of the encodings above have not actually been implemented yet. I will do so once I actually need them for the first time. Of course, you are free to implement them yourself, provided that the generated encodings comply with and do not contradict the above definitions.
