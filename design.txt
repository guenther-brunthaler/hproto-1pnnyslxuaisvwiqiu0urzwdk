hproto - Human-friendly binary protocol message encoding
========================================================

Introduction
------------

hproto is a binary protocol message encoding similar to Google's "protocol buffers", "MessagePack", "BENCODE" "ASN.1", "XDR" or the author's own "aproto".

It is used by a sending process to encode ("marshal") the data structure of a software message as an opaque block of binary data, which can then be transferred by any means available to a receiving process, which decodes ("un-marshals") and re-assembles an equivalent message for local processing.

The scope of application for hproto is also similar to that of XML, YAML, RFC-822 and JSON, except that hproto is not a text-based encoding.

The outstanding property of hproto is the fact that the encoding is simple enough that an encoded message can be decoded by a human with the help of a hexadecimal dump of the message contents relatively easily.

In this regard, hproto is similar to BENCODE, although the actual encoding is much more similar to "protocol buffers".

Like MessagePack, hproto also sacrifices some encoding efficiency for simplicity, resulting in an encoding which is less compact than "protocol buffers" or "aproto", but not by much.

hproto has also some provisions for optionally allowing to define messages in such a way so that they can be modified in-place. This is not as powerful als Google's "flatbuffers" which have been created explicitly for this purpose, but also much simpler to implement and understand.


Protocol definition syntax
--------------------------

Like "protocol buffers", hproto provides a metasyntax for defining the structure of a message. This information needs to be known by both the sender and receiver of a message in order to understand the contents of the message.

"protocol buffers" uses ".proto" text files for storing this metasyntax information, while hproto uses - little surprisingly - ".hproto" files for the same purpose.

It should be possible to write a message compiler for .hproto files which can validate the syntax of those files and then synthesize code for automatic marshalling and unmarshalling of hproto messages.

But this has not been done yet and may never be done, because hproto is simple enough that it can be assembled mostly manually. It can also be decoded visually using only a hex dump of the encoded message and a copy of the associated .hproto file as a reference.

OK, and now for an example how hproto works. Let's assume we have the follwing C struct

struct person {
   char *first_name, *last_name;
   unsigned int born;
}= {"John", "Doe", 1990};

and want to encode it as binary hproto message blob ("binary (potentially) large object") for transport.

First, we create a file "person.hproto" for this message, containing the following definition:

message person {
   string first_name: 0;
   string last_name: 1;
   uint born: 2;
};

This defines the fields which are allowed in the message and also assigned numeric field numbers to every field. The syntax for the field numbers looks similar to that of bit fields in C.

Other than the field names which are only required in the proto files, the field numbers will actually be part of the encoded binary message as "tags numbers".

Next, one needs to know the general encoding of a hproto message.


hproto Message "wire" Encoding
------------------------------

A hproto message encoding is an unordered collection of fields, much more like a hash rather than a C "struct". The fields within the message are identified by their tag number rather than by their order.

The actual message encoding is just a concatenation of field value encodings.

Each field value encoding has the following structure:

<type_octet> [ <tag_extension> ] [ <external_length> ] <field_contents>

Only <type_octet> and <field_contents> are actually necessary for every field, and <field_contents> has a variable size which can also be zero.

<type_octet> consists of two bitfields with 4 bits each, which will be represented by single hex-digits in a hexdump of the message:

* The left hex-digit of <type_octet> encodes the tag number of the field.
* The right hex-digit of <type_octet> encodes the byte size of the field contents.

The tag number is encoded directly within <type_octet> if its value is less than 0x0e. Otherwise, <tag_extension> is present and contains the actual tag number as a big-endian base-256 unsigned integer.

The byte size of the field contents is encoded directly within <type_octet> if its value is less than 0x0c. Otherwise, <external_length> is present and contains the actual tag number as a big-endian base-256 unsigned integer.

The byte size of the <tag_extension> field itself is determined by the value of the left hex-digit in <type_octet>: 1 if it is 0x0e, 2 if it is 0x0f, 0 otherwise.

The byte size of the <external_length> field itself is determined by the value of the right hex-digit in <type_octet>: 1 if it is 0x0c, 2 if it is 0x0d, 3 if it is 0x0e, 4 if it is 0x0f, 0 otherwise.

That's all one needs to know for the encoding of the basic message structure!


Example field contents encoding
-------------------------------

What is still required to know is how to encode the actual <field_contents>. This depends on the field type:

"string" is just encoded as the literal contents of the bytes which make up the string, not including the null terminator (in the case of C). An empty string is just represented by <field_contents> with a byte size of 0. Note that this is very different from an SQL-like "NULL"-value which would be represented by the whole field definition missing in the encoded message.

"uint" is the big-endian base-256 representation of the unsigned integer with as few bytes as possible (or with as many bytes as chosen in advance, for the intention of in-place editing). As a special optimization, an uint with a <field_contents> size of 0 bytes is allowed and then represents the numeric value zero. This might be a very useful optimization, because zero is a very frequent value in many applications.

This are all data types required for our example. See the section "data types" for more field types and their encodings.

So let's encode our example message now!

Fist, we encode the field values as hexadecimal bytes:

$ # string first_name: 0;
$ printf %s John | hexdump -C
00000000  4a 6f 68 6e                                       |John|
00000004

We encode this as the hex bytes

04 4a 6f 68 6e

The leading "04" is the <type_octet>. The "0" is the field tag for "first_name". The "4" is the length of the string. Then the string itself follows the <type_octet>.

$ # string last_name: 1;
$ printf %s Doe | hexdump -C
00000000  44 6f 65                                          |Doe|
00000003

We encode this as the hex bytes

13 44 6f 65

The "1" in the leading "13" is the field tag for "last_name". The "3" is the length of the string.

$ # uint born: 2;
$ printf '%x\n' 1990
7c6

We encode this as the hex bytes

22 07 c6

The left "2" in the leading "22" is the field tag for "born". The right "2" is the length of the field. The field itself contains the two bytes 07 c6, which represent the hexadecimal integer 0x07c6 (1990 in decimal).

The complete hproto message encoding is therefore:

04 4a 6f 68 6e 13 44 6f 65 22 07 c6

This has been easy because all tag numbers and field contents lengths could be represented directly within <type_octet> and neither <tag_extension> nor <external_length> where required.

So let's define a more complex message which needs both extended fields:

struct person2 {
   char *first_name;
   char *last_name;
   struct bigint *favorite_fermat_prime;
}= {
     UTF7_2_UTF8("G+APw-nther"), "Brunthaler"
   , STR_2_BIGINT("162259276829213363391578010288127")
}

message person2 {
   utf8_string first_name: 8;
   utf8_string last_name: 0x23;
   uint favorite_fermat_prime: 0x4567;
};

We use the type "utf8_string" here instead of just "string", because we want to use a particular encoding (UTF-8) for the contents of the string.

Note that we can actually use any types we want in the .hproto message definitions, because there is no compiler/verifier for it yet. It is strictly provided as a documentation of the intended message layout for the benefit of human developers.

As one can see, the field number tags in the hproto files must actually be provided as hexadecimal numbers. This was not obvious in our previous example because we only used tag numbers no larger than 9, which are the same in decimal and hexadecimal.

The reason why field numbers must be provided in hexadecimal is the fact that you will also see them in this form in the hex dump of a message.

We also remember from the explanation of the field number encoding that there are actually 3 different classes of field numbers which are encoded differently:

type_octet "Nx" with N from 0x00 through 0x0d
type_octet "ex" NN with NN from 0x00 through 0xff
type_octet "fx" NN NN with NNNN from 0x0000 through 0xffff

where "x" does not matter (it represents the field length).

Now let's encode the actual fields:

$ # utf8_string first_name: 8 = UTF7_2_UTF8("G+APw-nther")
$ printf %s G+APw-nther | iconv -f UTF-7 -t UTF-8 | hexdump -C
00000000  47 c3 bc 6e 74 68 65 72                           |G..nther|
00000008

This are 8 UTF-8 bytes with field tag 8, which will be encoded as

88 47 c3 bc 6e 74 68 65 72

$ # utf8_string last_name: 0x23 = "Brunthaler"
$ printf %s Brunthaler | iconv -t UTF-8 | hexdump -C
00000000  42 72 75 6e 74 68 61 6c  65 72                    |Brunthaler|
0000000a

This are 0x0a bytes with field tag 0xe23, which will be encoded as

ea 23 42 72 75 6e 74 68 61 6c 65 72

Here the "23" are the <tag_extension> which is present because the initial "e" defines a 1-byte <tag_extension> to be present. The "a" in the "ea" is the byte length of the UTF-8 encoded string, and the remaining bytes represent the string contents.

$ # uint favorite_fermat_prime: 0x4567 = STR_2_BIGINT("162259276829213363391578010288127"
$ echo "obase=16; 162259276829213363391578010288127" | bc | tr A-F a-f | { read x; expr ${#x} % 2 != 0 > /dev/null && x=0$x; printf '%02x\n' `expr ${#x} / 2`; echo $x | fold -w 2 | paste -s -d " "; }
0e
07 ff ff ff ff ff ff ff ff ff ff ff ff ff

The first line of the output is the number (0x0e) of the following bytes, and the second line is just the hexadecimal representation of the large prime number. We encode this as

fc 45 67 0e 07 ff ff ff ff ff ff ff ff ff ff ff ff ff

The "f" in the "fc" means that we use a 2-byte <tag_extension>, which is represented by the bytes "45 67" which are the big-endian base-256 representation of the value 0x4567.

The "c" in the "fc" means that the length of the contents is too large to be encoded directly as the 2nd hex digit of the <type_octet>. Instead, a 1-byte <external_length> is used to represent the actual length. This is the byte "0e" in the encoding. The remaining bytes represent the prime number as an unsigned integer with the value 0x07ffffffffffffffffffffffffff.

Together, the complete message hproto-encodes as

88 47 c3 bc 6e 74 68 65 72 ea 23 42 72 75 6e 74 68 61 6c 65 72 fc 45 67 0e 07 ff ff ff ff ff ff ff ff ff ff ff ff ff


Here is a chart for decoding hproto messages from left to right based on their hex dump:

0? - d?: Tag number is directly encoded as 0x00 through 0x0d.
e?: Tag number follows as 1 byte
f?: Tag number follows as 2 bytes (big-endian base-256 representation)
?0 - ?b: Field contents byte length is directly encoded as 0x00 through 0x0b.
?c: Contents length follows as 1 byte
?d: Contents length follows as 2 bytes (big-endian base-256 representation)
?e: Contents length follows as 3 bytes (big-endian base-256 representation)
?f: Contents length follows as 4 bytes (big-endian base-256 representation)

In all cases, the optional <tag_extension> precedes the optional <external_length>, and both are located between the <type_octet> and the optional <field_contents>.

After those examples, some clarifications.

There are no "required" fields in a message. All fields can be missing, which will then behave like a "NULL" value in SQL (i. e. "value not present").

message person {
   string first_name: 0;
   string last_name: 1;
   opt married: 2;
};

If the type "opt" is implemented as an empty string (encoded as "20" for tag number 2 and zero length) and the presence of the field means the option applies, then the missing field means that the option does not apply.

That is, the presence of a "20" field encoding as a message field means the person is married. Otherwise the person is not married.

It is also possible to define a default value in the hproto file. If the field is missing in the message, then the field is assumed to have the default value as its contents.

message person {
   string first_name: 0;
   string last_name: 1;
   string marital_status: 2 = "single";
};

This means that if a field with tag number 2 is present then it represents the marital status as a string. Otherwise, the string "single" will be used as the status even though it is not actually present in the message and would be NULL without the default declaration.

When creating a message, a field can be omitted from the encoding if the value to be encoded equals the field's default value. This is just an optimization, though, and not a requirement.

So far, the length of the <field_contents> have always been determined by the minimum number of bytes required to represent the contents.

However, for messages which are to be edited in-place, it might be a good idea to make the field length that of the maximum supported length of the content.

For instance, if we want to store a 24-bit RGB color encoded as an unsiged integer 0xRRGGBB

message rgb_color {
   uint rgb24: 9;
};

then the color black 0x000000 could easily be encoded as

90

(remember that an uint of size 0 represents the value zero) because 0x000000 and 0 are the same integer.

However, if we want to make this message editable in-place, we need to ensure that it will always use 3 bytes for the encoding, even if it means to store leading zeros, so that the value can be replaced with an arbitrary RGB value later.

This can be enforced as follows:

message rgb_color {
   uint rgb24: 9 (zero-leftpad to 3 octets);
};

This means that if the field contents need less then 3 bytes to encode, then it will be padded to 3 bytes by adding zero bytes at the left. "zero-rightpad" does the same but adds the pad bytes at the right side (this type of padding is useful for strings).

The term "octet" is used instead of "byte" to make clear that 8-bit bytes are meant. Historically, bytes with bit sizes other than 8 bits are known to have existed on some hardware platforms. "octet" always means an "8 bit byte".

Generally, a comma-separated list of such and similar attribute declarations can be placed within parentheses before the end of the field declaration.

Like for tag numbers, only hexadecimal numbers are allowed for zero-rightpad declarations in order to avoid base conversions when examining the hexdump of a message. And again the 0x-prefix is optional for hex numbers up to 9.

In the case of this example, "3" means direct encoding within the <type_octet>. It ensures that the color black would be encoded as

93 00 00 00

The "9" is the tag number, the "3" is the field contents width directly encoded in the <type_octet>, and the "00 00 00" is the 24-bit fixed-width RGB encoding of black.

Another example:

message nested_string {
   string text: 6;
};

message song {
   uint track: 3 (zero-leftpad to 1 octet);
   nested_string artist: 5 (zero-rightpad to 0x20 octets);
   nested_string title: 7 (zero-rightpad to 0x40 octets);
   nested_string description: 4 (zero-rightpad to 0x400 octets);
};

Such a message will have the following encoding:

31 <track_uint> 5c 20 <artist_string>... 7c 40 <title_string>... 4d 04 00 <description>...

Note that the fields ending with "..." are nested fields which include their own length. The idea is that the "inner" length specifications define the actual length of the field contents, where the zero-rightpad width just ensures that there is enough space for increasing the inner length in-place.


Field data types
----------------

The basic hproto wire-encoding does not care about field types. They must be learned by looking into the declarations of the *.hproto files. The wire-encoding treats all data types just as opaque octet-strings.

The following list gives a list of type names which can be used to declare particular data type encodings for fields within *.hproto files.

You are invited to invent your own data types in addition to those declared here. However, the types declared here shall always be interpreted as described here. If you don't like those encodings, just don't use them and create your own encodings using with other names instead.

* A nested message. This is actually not a particular name, but is rather represented by the name given to a different "message" declaration. Such defined message types can be used as fields in other messages. This is encoded as a byte string, i. e. the field is encoded like a string and contains the complete hproto-encoding of the nested message as its contents.

* "uint" - an unsigned integer of arbitrary magnitude, encoded as a big-endian integer (written from left to right starting with the most significant digit and followed with increasingly less significant digits). This encoding uses a number-system with radix 256, where every "digit" is represented by an octet. Therefore, the shortest possible encoding for integer 0x12345 will be the byte-sequence 01 23 45. As an optimization, an "empty" uint (i. e. one with a <field_contents> length of 0 bytes) is defined to represent the value 0. Note that this encoding is quite different from Google's "protocol buffers" which use a much more complicated base-128 encoding which requires bit-shifting to decode/decode the values. The hproto "uint"-encoding does not require any bit-shifting.

* "int" - a signed integer of arbitrary magnitude. This is encoded as an "uint" after "zig-zag"-encoding the signed integer value as an unsigned integer. Zig-zag-encoding maps signed integers into unsigned ones as follows: 0, -1, 1, -2, 2, -3, 3, -4, 4, ... are mapped to unsigned 0, 1, 2, 3, 4, 5, 6, 7, 8, ..., respectively. The encoding alternates by describing the next unsigned number and the next signed number not yet described. The unsigned numbers start with 0 and the signed numbers start with -1. Note that this zig-zag-encoding has been "borrowed" from Google's protocol buffers.

* "string", "locale_string", "any_string" - a text string of unspecified encoding or character set. Use this to pass through string values where the encoding is unknown or subject to change. Use "any_string" if the string is known to potentially use different character sets or character encoding depending on the circumstances or changes regularly. Use "string" if you just don't care about the character encoding, and don't even want to know such details. Use "locale_string" if the string will use the character set and encoding defined by the locale which is currently in effect, whatever it may be.

* "octetstring", "bytestring" and "opaque" - a string containing binary bytes that are not necessarily text but may as well be such. The name "bytestring" is deprecated. "octetstring" should be used it it is important/relevant that the string consists of 8-bit bytes. "opaque" should be used to describe a BLOB of data without known (or cared about) internal structure.

* "utf8_string" - a UNICODE string in UTF-8 encoding without a particular normalization form. That is, such a strings may contain a mixture of NFC- and NFD-encoded UNICODE characters.

* "utf16_le_string" - a UNICODE string in UTF-16LE encoding without a particular normalization form (see "uft8_string"). No BOM is used, little-endian representation is mandatory.

* "utf16_le_string" - a UNICODE string in UTF-16BE encoding without a particular normalization form (see "uft8_string"). No BOM is used, big-endian representation is mandatory.

* "utf16_default_le_string" - a UNICODE string in UTF-16 encoding without a particular normalization form (see "uft8_string"). A BOM may be used to indicate the byte order. Without a BOM, the byte order must be little-endian.

* "utf16_default_be_string" - a UNICODE string in UTF-16 encoding without a particular normalization form (see "uft8_string"). A BOM may be used to indicate the byte order. Without a BOM, the byte order must be big-endian.

* "latin1_string" - a UNICODE string which is restricted to the first 256 UNICODE code points, also known as the LATIN1 or ISO-8859-1 character set. Note that this type is probably not very useful any more as it cannot represent the EURO sign. However, it is the most compact encoding of UNICODE which does not contain any multi-byte encodings. It is also a superset of ASCII and contains most umlauts and diacritics used by western languages.

* "ascii" - a UNICODE string which is restricted to the first 128 UNICODE code points, also known as ASCII, US-ASCII or IA85. It represents all characters als octets with the most significant bit set to 0.

* "ebcdic" - this is just included for completeness. EBCDIC is a character set mostly used on ancient IBM mainframes. It has little significance nowadays, but may still be encountered when dealing with historic data records or ancient applications. It is a 7-bit character set like ASCII, but assigns the characters in a different way to codepoints.

* "boolean": A restricted subtype of "uint" where only the values 0 and 1 are allowed. Note that this is actually a tri-state rather than a real boolean value, because the value can also be NULL if the field is not present at all in the message encoding. NULL could then be interpreted as a third state "maybe" or "undecided". Encoded the same as "uint", including the optimization that an empty <field_contents> represents the value 0 (and thus "false"). However, when defining a default value for such a field, only the words "true" and "false" shall be allowed in a message definition. You can define your own "bool" if you don't like this definition.

* "float": Default value is +0. A single-precision floating-point number, using exactly the exact same bit layout as a "float" in the C programming language on the local machine. This type is inherently hardware-specific and may even depend on compiler options. It is therefore non-portable. However, it is normally safe to use for communication between different processes running on the same machine, of if the communication is restricted to other machines sharing the same floating point format details. It has also the advantage of zero conversion overhead.

* "double": Default value is +0. A double-precision floating point number. See the documentation for type "float", replacing any referenced to the term "float" with "double".

* "pfloat": Default value is +0. A portable floating point number. This is in fact a predefined "message pfloat {int mantissa:0; uint radix:1 = 2; int exponent:2 = 0}" which contains everything necessary to represent a floating point number of any radix base from any platform with maximum precision portably and exactly. This type may have a shorter or longer encoding than "float" and "double", depending on the bit pattern of the value to be encoded. Use this type for portable communication between machines with unknown or different internal floating point implementations or byte orders. Note that <mantissa> is usually more than just the mantissa of a "float"/"double", as it actually includes its most significant bit as well as the sign of the number. The value of the exponent will also be adjusted to compensate for the fact that <mantissa> is an integer rather than a fractional value. Special values are represented by <mantissa> == 0 with the following predefined values for <exponent> in those cases: +0.0 == 0, -0.0 == -1, +INF == +2, -INF == -2, NaN == +3, IND/QNaN == -3. "INF" means "Infinity", "NaN" means "Not a Number", "QNaN" means "Quiet/Signaling NaN", "IND" means "indeterminate number". Denormal numbers need no special encoding in this definition because they are not necessary. Note that while this format can store all known floating-point formats without loss of precision, this does not mean that your platform's native floating-point support can do the same. This means that a conversion from float or double into "pfloat" is intended to be lossless, but this may not be true in the opposite direction. But even if some rounding might be unavoidable when converting to a native "double" depending on the platform, "pfloat" is still your best option of exchanging binary floating point numbers in the most platform-neutral way possible. Also note that not all platforms may support all features of "pfloat" such as NaNs - the conversion might fail in such cases, and need to be handled specially by the application. As a finishing remark, note that you always the option of using a portable software library such as libmpfr which supports arbitrary precision, rather than using your platform's native floating-point support.

* "decimal": This is a radix-10 floating point number with an integer mantissa and a non-positive exponent. Which means the exponent only expresses how many of the right-hand digits of the mantissa are fractional digits, but it cannot shift the mantissa to the left. "decimal" can store decimal numbers with any number of integral and fractional digits exactly. This are in fact implemented as a predefined "message decimal {int integral:0 = 0; uint base10_exponent:1 = 0}". For simplicity, there is no support for "special" values like NaN or INF when mantissa == 0 - the exponent has no effect in that case and should also be 0 to save space (but this is no requirement). If you want such special values, use "pfloat" instead which also can represent decimal fractional digits exactly. Actually, "decimal" is very similar to "pfloat", except that it implies a radix of 10 and normalization is somewhat easier, because the exponent can never be positive. Most of the time, "dfix_4" will produce shorter encodings than "decimal". But "decimal" can store an unrestricted number of fractional digits exactly.

* "dfix_1": This is a decimal number with exactly one fractional digit. It is simply stored multiplied by 10 as an "int". This type is more space-efficient than "dfix_4" if the fractional digit is frequently different from zero. Otherwise, if its is known that the vast majority of values to be encoded are in fact integral values without a fractional digit, "dfix_4" will be more space-efficient.

* "dfix_2": This is a decimal number with exactly two fractional digits. It is simply stores multiplied by 100 as an "int". Note that this encoding might actually be longer than that of "dfix_4" if there are trailing fractional zero digits.

* "dfix_4": This is a decimal number which can store up to 4 fractional digits. Actually, it can store either 0, 1, 2 or 4 decimal digits. A "dfix_4" is internally stored as an "uint", which is composed of two values: m * 4 + f. That is, "f" is a 2-bit bitfield, and "m" is the remaining arbitrarily-sized integer part. "m" will then further be interpreted as a signed "int" (using zig-zag-encoding), and "f" determines the number of fractional decimal digits which are present at the right-hand side of the (now signed) "m". This number of fractional digits calculates as follows from "f": 2 raised to the power of "f", then reduced modulo 8. (In C this can be calculated as "1 << f & 7".) In other words, f == 0 means 1 fractional digit, f == 1 means 2 digits, f == 2 is 4 digits, and f == 3 means no fractional digits at all. "dfix_4" is well suited to space-efficiently store monetary amounts for most currencies which rarely need more than 2 or 4 fractional digits. It may not be accurate enough to store bitcoin fractional values, though. Use a "decimal" in those cases which can store an unrestricted amount of fractional decimal digits exactly.

* "rational": This is in fact a predefined "message rational {int numerator:0 = 1; uint denominator:1 = 1}" which contains everything necessary store a fraction exactly. The fraction does not need to be normalized, although the application is of course free to do so. The following special values are supported: INF == +1/0, -INF == -1/0, IND/QNaN == 0/0. Note that there are an infinite number of additional ways to represent INF and -INF, but only the values above shall be taken as actual synonyms. There is no plain NaN. It is implementation-defined whether display formatting functions use the symbolic names or just display numerator and denominator as-is, i. e. as numbers.

* "bitvector": This is a binary packed array of bits, stored as an octetstring. The first octet stores the bits with indexes 0-7, the second octet stores bits 8-15, etc. Within every octet, the least significant bit stores the bit with the lowest array index of that octet, and the most significant bit refers to the highest array index of that octet. It is allowed to write bits beyond the current actual size of the array, bitvector will automatically be enlarged if necessary. There is an infinite number of virtual "0"-bits beyond the last actually allocated octet in the array, which will be returned when reading without growing the array. This allows the optimization that a "bitvector" with 0 octets of <field_contents> will actually represent a vector filled with infinite many "0" bits. Also, writing a "0"-bit will never grow the array for the same reason. The API shall provide the information what the highest actually allocated bitvector-index is. Because bits are not necessarily booleans, the values "0" and "1" are considered to be small integers, rather than abstract symbols like "true" or "false".

* "serialdate": The number of days between 2000-01-01 and a given target date at the same place, both dates specified in the local time of that place. This number is internally expressed (and encoded as) an "int". That is, 2000-01-01 is encoded as 0, 2000-01-02 is encoded as +1, 1999-12-31 is encoded as -1, etc. The calculations are done using the rules of the Gegorian calender, which is the standard in Western countries, and was introduced on 1582-10-15, which is also the earliest date which should be represented as a "serialdate". Leap seconds cannot have any effect on the calculation, because only whole days are considered.

* "tzoffset": The offset of some time zone (typically the local one) from UTC, encoded as an "int", expressed as 15-minute-intervals (most time zone offsets are whole hours, but some are offset by 30 or 45 minutes - all of those can be expressed as multiples of 15 minute intervals). The value 0 means UTC. In other words, time_as_UTC + 15 * tzoffset * minutes == time_in_associated_timezone.

* "serialtime": The number of seconds elapsed since midnight of some day at some place, always using the time zone offset which was in effect at exactly that time at that place. Let's say, at the start of that day daylight saving was not in effect, but later that day it became effective. If serialtime is calculated from a time before daylight saving became active, it is based on the same "tzoffset" as the start of the day. Otherwise, it is based on the same "tzoffset" as the next day, which already includes the daylight saving offset. It assumes all minutes have exactly 60 seconds. The conversion of "serialtime" and HH:MM:SS is based on calendar time, and will not care about leap seconds (encoding some time [$MM]:60 will decode incorrectly as [$MM+1]:00 - the Linux "date" utility has exactly the same problem). This means "serialtime"-values will never be larger than 24 hours, even if daylight saving started or ended during that day. Even though the conversion itself does not care about leap seconds, the operating system functions which get the current HH:MM:SS normally do. So, as long as the time is actually obtained from such a function before converting it to "serialtime", the time expressed by that "serialtime" value will be correct subtracting two such values will usually calculate the correct time difference, including any leap seconds. This assumes the time stamps are from the same place and date, however. Otherwise, you need to include the "tzoffset" as well as the "serialdate" in the calculation as well, or the timestamps will not be comparable.

* "localdatetime": This is in fact a predefined "message localdatetime {serialdate date:0; serialtime time:1 = 0}" which contains everything necessary to compare two timestamps taken at the same place (with regard to the timezone) on possibly different dates.

* "globaldatetime": This is in fact a predefined "message globaldatetime {serialdate date:0; serialtime time:1 = 0; tzoffset tzo15m:2 = 0}" which contains everything necessary to compare two timestamps taken at two possibly different places (with regard to the timezone) on possibly different dates. Note that the timezone resulting from the default value for tzo15m will be UTC.


Adding custom type names
~~~~~~~~~~~~~~~~~~~~~~~~

The above list is *not* intended to ever be extended, which might otherwise create future name collisions. So there is no need to name your types X-something out of fear of future enhancements of hproto. Name your own type "int32" or "complex" if you like. Of course, defining any new types creates a responsibility for you to document the details of your encoding, preferrably as comments (or at least a reference where the details can found) in the hproto definition file.


Notable missing predefined data types
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Even though it is possible to add any desired missing data type as custom type names, I will explain here why some popular data types have not been predefined.


int32, int64 etc.
^^^^^^^^^^^^^^^^^

The existing "int"/"uint" can represent each of those without any disadvantage in terms of encoding efficiency. Together with the "zero-leftpad"-attribute declaration fixed-width encodings of are also possible.

utf32_string
^^^^^^^^^^^^

UTF-32 encoding is only interesting as an in-memory representation for simpler processing. It makes no sense as an external encoding, because there is no UTF-32 encoding which cannot be replaced by a same-length or shorter equivalent UTF-16 encoding. An UTF-32 encoding of some text is always larger or the same length as UTF-16, but will never save space. Generally, western languages are most efficiently encoded as UTF-8, while eastern CJK languages are most efficiently encoded as UTF-16.


UNICODE normalization qualifiers
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For those of the above UNICODE-based string types which can potentially represent UNICODE characters normalized as NFD, the type name may optionally be preceded by one of the following qualifiers: NFC, NFD, NFKC, NFKD. Those specify that the string values for that field are required to be normalized according to the UNICODE normalization format of the same name. If you have no idea what UNICODE normalization is, you probably won't need it. The qualifiers mean that any specified default constant for such a string must be normalized in the same way, because the protocol compiler won't convert anything. However, it MAY present an error in such a case (more likely though it won't care). Neither is the run-time required to check for normalization compliance (though it might). Therefore, those qualifiers are primarily a hint to the human reader what sort of normalization is expected/required.


UNICODE compression qualifiers
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For those of the above UNICODE-based string types which uses multibyte encodings for at least some of its UNICODE characters, and preceding the UNICODE normalization qualifier (if any as it is optional), one of two further optional qualifiers is allowed: "SCSU-compressed" and "BOCU-1-compressed". They declare that the UNICODE string in this field is expected to be compressed with the compression scheme named after the qualifier. It also means that any declared default value will be encoded this way before actually being used. Like the normalization qualifiers, those compression qualifiers will have no effect on the run-time or the protocol compiler, other than compressing any associated default string literal in the specified way. And the first version of the protocol compiler certainly won't support that, meaning that for now string fields with that qualifier must not have an explicit default value.


Current state of implementation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Finally note that most of the encodings above have not actually been implemented yet. I will do so once I actually need them for the first time. Of course, you are free to implement them yourself, provided that the generated encodings comply with and do not contradict the above definitions.
